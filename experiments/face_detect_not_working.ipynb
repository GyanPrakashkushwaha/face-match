{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\vscode_machineLearning\\\\BEST_PROJECTS\\\\face-match\\\\experiments'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('d:\\\\vscode_machineLearning\\\\BEST_PROJECTS\\\\face-match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_pkl, dump_pkl\n",
    "import numpy as np\n",
    "from src.constants import MODEL\n",
    "from mtcnn import MTCNN \n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from src.exceptions import CustomException\n",
    "import sys\n",
    "from src.logger import logger\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "def detect_face(image_path):\n",
    "    try:\n",
    "        logger.info(f\"Loading image from {image_path}.\")\n",
    "        sample_img = cv2.imread(image_path)\n",
    "        logger.info(\"Detecting face in the image.\")\n",
    "        detected_face = detector.detect_faces(sample_img)\n",
    "        \n",
    "        if len(detected_face) == 0:\n",
    "            raise CustomException(\"No face detected in the image.\", sys)\n",
    "        \n",
    "        X, y, width, height = detected_face[0]['box']\n",
    "        face = sample_img[y:y+height, X:X+width]\n",
    "        img = Image.fromarray(face)\n",
    "        img = img.resize(size=(224, 224))\n",
    "        face_array = np.asarray(img).astype(np.float32)\n",
    "\n",
    "        return face_array\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in detect_face method: {e}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "sample_img = cv2.imread(os.path.join('uploaded_images','Abhay_Deol.15.jpg'))\n",
    "detected_face = detector.detect_faces(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidImage",
     "evalue": "Image not valid.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidImage\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m sample_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39muploaded_images\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mAbhay_Deol.15.jpg\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[39m# logger.info(\"Detecting face in the image.\")\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m detected_face \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39;49mdetect_faces(sample_img)\n",
      "File \u001b[1;32md:\\vscode_machineLearning\\BEST_PROJECTS\\face-match\\faceenv\\lib\\site-packages\\mtcnn\\mtcnn.py:287\u001b[0m, in \u001b[0;36mMTCNN.detect_faces\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[39mDetects bounding boxes from the specified image.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39m:param img: image to process\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[39m:return: list containing all the bounding boxes detected with their keypoints.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39mif\u001b[39;00m img \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(img, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 287\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidImage(\u001b[39m\"\u001b[39m\u001b[39mImage not valid.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m height, width, _ \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape\n\u001b[0;32m    290\u001b[0m stage_status \u001b[39m=\u001b[39m StageStatus(width\u001b[39m=\u001b[39mwidth, height\u001b[39m=\u001b[39mheight)\n",
      "\u001b[1;31mInvalidImage\u001b[0m: Image not valid."
     ]
    }
   ],
   "source": [
    "sample_img = cv2.imread(os.path.join('uploaded_images','Abhay_Deol.15.jpg'))\n",
    "# logger.info(\"Detecting face in the image.\")\n",
    "detected_face = detector.detect_faces(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faceenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
